{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1d1b8dda",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "import re\n",
    "import string\n",
    "import warnings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "7c6f7ea8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "os.environ['KERAS_BACKEND'] = 'tensorflow'\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, LSTM, SpatialDropout1D, SimpleRNN\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a38f035d",
   "metadata": {},
   "source": [
    "## Data Loading\n",
    "### Load cleaned data from data_preprocessing pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "94eda10d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>awww bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>upset updat facebook text might cri result sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>dive mani time ball manag save rest bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>behav mad see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                              words\n",
       "0  0       awww bummer shoulda got david carr third day\n",
       "1  0  upset updat facebook text might cri result sch...\n",
       "2  0          dive mani time ball manag save rest bound\n",
       "3  0                    whole bodi feel itchi like fire\n",
       "4  0                                      behav mad see"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data_path = \"./clean_train.csv\"\n",
    "df_train = pd.read_csv(train_data_path)\n",
    "df_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d0cdd25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>awww bummer shoulda got david carr third day</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>upset updat facebook text might cri result sch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>dive mani time ball manag save rest bound</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>whole bodi feel itchi like fire</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>behav mad see</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   0                                              words\n",
       "0  0       awww bummer shoulda got david carr third day\n",
       "1  0  upset updat facebook text might cri result sch...\n",
       "2  0          dive mani time ball manag save rest bound\n",
       "3  0                    whole bodi feel itchi like fire\n",
       "4  0                                      behav mad see"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data_path = \"./clean_test.csv\"\n",
    "df_test = pd.read_csv(test_data_path)\n",
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5e7d1e5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove empty entries\n",
    "df_train = df_train[df_train['words'].notna()]\n",
    "df_test = df_test[df_test['words'].notna()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f76a637d",
   "metadata": {},
   "source": [
    "## Tokenize for model input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ca307a4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words = 2000, split = ' ')\n",
    "tokenizer.fit_on_texts(df_train['words'].astype(str).values)\n",
    "train_tweets = tokenizer.texts_to_sequences(df_train['words'].astype(str).values)\n",
    "max_len = max([len(i) for i in train_tweets])\n",
    "train_tweets = pad_sequences(train_tweets, maxlen = max_len)\n",
    "test_tweets = tokenizer.texts_to_sequences(df_test['words'].astype(str).values)\n",
    "test_tweets = pad_sequences(test_tweets, maxlen = max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18754185",
   "metadata": {},
   "source": [
    "## Deep Learning methods\n",
    "### LSTM Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b028c7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, 27, 256)           512000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d (SpatialDr (None, 27, 256)           0         \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, 256)               525312    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 1,037,826\n",
      "Trainable params: 1,037,826\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model architecture\n",
    "model = Sequential()\n",
    "model.add(Embedding(2000, 256, input_length = train_tweets.shape[1]))\n",
    "model.add(SpatialDropout1D(0.4))\n",
    "model.add(LSTM(256, dropout = 0.2))\n",
    "model.add(Dense(2, activation = 'softmax'))\n",
    "model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2f27fa03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3106/3106 [==============================] - 138s 38ms/step - loss: 0.4918 - accuracy: 0.7595\n",
      "Epoch 2/10\n",
      "3106/3106 [==============================] - 119s 38ms/step - loss: 0.4771 - accuracy: 0.7690\n",
      "Epoch 3/10\n",
      "3106/3106 [==============================] - 119s 38ms/step - loss: 0.4709 - accuracy: 0.7731\n",
      "Epoch 4/10\n",
      "3106/3106 [==============================] - 119s 38ms/step - loss: 0.4653 - accuracy: 0.7764\n",
      "Epoch 5/10\n",
      "3106/3106 [==============================] - 117s 38ms/step - loss: 0.4606 - accuracy: 0.7788\n",
      "Epoch 6/10\n",
      "3106/3106 [==============================] - 116s 37ms/step - loss: 0.4561 - accuracy: 0.7817\n",
      "Epoch 7/10\n",
      "3106/3106 [==============================] - 119s 38ms/step - loss: 0.4521 - accuracy: 0.7842\n",
      "Epoch 8/10\n",
      "3106/3106 [==============================] - 119s 38ms/step - loss: 0.4483 - accuracy: 0.7862\n",
      "Epoch 9/10\n",
      "3106/3106 [==============================] - 118s 38ms/step - loss: 0.4448 - accuracy: 0.7885\n",
      "Epoch 10/10\n",
      "3106/3106 [==============================] - 119s 38ms/step - loss: 0.4414 - accuracy: 0.7905\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efe28b4cd30>"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "model.fit(train_tweets, pd.get_dummies(df_train['0']).values, epochs = 10, batch_size = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "138636ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3106/3106 [==============================] - 39s 12ms/step - loss: 0.4195 - accuracy: 0.8029\n",
      "Test accuracy: 0.8029493093490601\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "score, accuracy = model.evaluate(test_tweets, pd.get_dummies(df_test['0']).values, batch_size = 512)\n",
    "print(\"Test accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba7b4f78",
   "metadata": {},
   "source": [
    "### RNN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "01655313",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 27, 256)           512000    \n",
      "_________________________________________________________________\n",
      "spatial_dropout1d_1 (Spatial (None, 27, 256)           0         \n",
      "_________________________________________________________________\n",
      "simple_rnn (SimpleRNN)       (None, 256)               131328    \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 514       \n",
      "=================================================================\n",
      "Total params: 643,842\n",
      "Trainable params: 643,842\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# model architecture\n",
    "RNNmodel = Sequential()\n",
    "RNNmodel.add(Embedding(2000, 256, input_length = train_tweets.shape[1]))\n",
    "RNNmodel.add(SpatialDropout1D(0.4))\n",
    "RNNmodel.add(SimpleRNN(256, dropout = 0.2))\n",
    "RNNmodel.add(Dense(2, activation = 'softmax'))\n",
    "RNNmodel.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "RNNmodel.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6d313234",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "3106/3106 [==============================] - 89s 28ms/step - loss: 0.5118 - accuracy: 0.7489\n",
      "Epoch 2/10\n",
      "3106/3106 [==============================] - 88s 28ms/step - loss: 0.4959 - accuracy: 0.7606\n",
      "Epoch 3/10\n",
      "3106/3106 [==============================] - 88s 28ms/step - loss: 0.4881 - accuracy: 0.7633\n",
      "Epoch 4/10\n",
      "3106/3106 [==============================] - 87s 28ms/step - loss: 0.4851 - accuracy: 0.7648\n",
      "Epoch 5/10\n",
      "3106/3106 [==============================] - 87s 28ms/step - loss: 0.4831 - accuracy: 0.7657\n",
      "Epoch 6/10\n",
      "3106/3106 [==============================] - 87s 28ms/step - loss: 0.4816 - accuracy: 0.7667\n",
      "Epoch 7/10\n",
      "3106/3106 [==============================] - 87s 28ms/step - loss: 0.4792 - accuracy: 0.7679\n",
      "Epoch 8/10\n",
      "3106/3106 [==============================] - 86s 28ms/step - loss: 0.4778 - accuracy: 0.7687\n",
      "Epoch 9/10\n",
      "3106/3106 [==============================] - 86s 28ms/step - loss: 0.4764 - accuracy: 0.7694\n",
      "Epoch 10/10\n",
      "3106/3106 [==============================] - 86s 28ms/step - loss: 0.4754 - accuracy: 0.7701\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7efe1c4a9a90>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train model\n",
    "RNNmodel.fit(train_tweets, pd.get_dummies(df_train['0']).values, epochs = 10, batch_size = 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2a9dcfdf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3106/3106 [==============================] - 22s 7ms/step - loss: 0.4692 - accuracy: 0.7741\n",
      "Test accuracy: 0.7740947008132935\n"
     ]
    }
   ],
   "source": [
    "# test model\n",
    "RNNscore, RNNaccuracy = RNNmodel.evaluate(test_tweets, pd.get_dummies(df_test['0']).values, batch_size = 512)\n",
    "print(\"Test accuracy: {}\".format(RNNaccuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "59836fed",
   "metadata": {},
   "source": [
    "Overall, the best performing model is the LSTM model and the worst performing model is SVM. The deep learning models performed better than the classical machine learning methods. This is probably due to their ability to process recurrence. In particular, LSTM performed better than RNN because of its ability to remember information from previous timesteps. As discovered in data_preprocessing, some words occur in both positive and negative tweets, hence the sentiment really depends on context, not individual words, hence RNN and LSTM which takes in timestep information is more useful in predicting sentiments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "913a30ed",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernel_info": {
   "name": "azureml_py38_tensorflow"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
